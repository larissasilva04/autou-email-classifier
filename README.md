ğŸ“§ AutoU Classificador de Emails
Sistema inteligente de classificaÃ§Ã£o de emails e geraÃ§Ã£o de respostas automÃ¡ticas desenvolvido para o processo seletivo da AutoU.
ğŸ¯ VisÃ£o Geral
Esta aplicaÃ§Ã£o utiliza inteligÃªncia artificial para:

Classificar emails em categorias "Produtivo" ou "Improdutivo"
Gerar respostas automÃ¡ticas apropriadas para cada categoria
Processar arquivos .txt e .pdf ou texto direto
Interface moderna e intuitiva baseada no design da AutoU

ğŸš€ Demo
Link da aplicaÃ§Ã£o: https://seu-app.vercel.app
Exemplos de Uso
Email Produtivo:
Assunto: Problema com login no sistema
Estou enfrentando dificuldades para acessar...
â†’ ClassificaÃ§Ã£o: Produtivo (85% confianÃ§a)
â†’ Resposta: Email de suporte tÃ©cnico profissional
Email Improdutivo:
Assunto: Feliz AniversÃ¡rio!
ParabÃ©ns pelo seu aniversÃ¡rio...
â†’ ClassificaÃ§Ã£o: Improdutivo (92% confianÃ§a)  
â†’ Resposta: Agradecimento caloroso e cordial

ğŸ› ï¸ Tecnologias Utilizadas

Frontend

HTML5 SemÃ¢ntico com estrutura acessÃ­vel
CSS3 AvanÃ§ado com animaÃ§Ãµes e gradientes
JavaScript Vanilla para interaÃ§Ãµes dinÃ¢micas
Design System baseado na identidade visual da AutoU

Backend

Python 3.8+ como linguagem principal
Flask para API REST
OpenAI GPT-3.5 para classificaÃ§Ã£o inteligente
NLTK para processamento de linguagem natural
PyPDF2 para leitura de arquivos PDF

Deploy e Infraestrutura

Vercel para hospedagem gratuita
Git/GitHub para controle de versÃ£o
Environment Variables para configuraÃ§Ã£o segura

ğŸ“ Estrutura do Projeto
AUTO U/
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html          # Interface principal
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Servidor Flask principal
â”‚   â”œâ”€â”€ email_processor.py  # Processamento de emails
â”‚   â”œâ”€â”€ classifier.py       # ClassificaÃ§Ã£o com IA
â”‚   â”œâ”€â”€ response_generator.py # GeraÃ§Ã£o de respostas
â”‚   â”œâ”€â”€ analytics.py        # Sistema de mÃ©tricas
â”‚   â””â”€â”€ requirements.txt    # DependÃªncias Python
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_classifier.py  # Testes automatizados
â”œâ”€â”€ vercel.json            # ConfiguraÃ§Ã£o de deploy
â”œâ”€â”€ .env.example           # Exemplo de variÃ¡veis de ambiente
â””â”€â”€ README.md             # Esta documentaÃ§Ã£o

âš¡ InstalaÃ§Ã£o e Uso
1. PrÃ©-requisitos

Python 3.8 ou superior
Conta na OpenAI (para chave da API)
Node.js (para deploy na Vercel)

2. ConfiguraÃ§Ã£o Local
bash# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/email-classifier.git
cd email-classifier

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate # Windows

# Instale dependÃªncias
pip install -r backend/requirements.txt

# Configure variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com sua OPENAI_API_KEY
3. ExecuÃ§Ã£o Local
bash# Execute o servidor de desenvolvimento
cd backend
python app.py

# Acesse http://localhost:5000
4. Testes
bash# Execute os testes automatizados
python tests/test_classifier.py
ğŸŒ Deploy na Vercel
1. ConfiguraÃ§Ã£o da Vercel
bash# Instale a CLI da Vercel
npm i -g vercel

# FaÃ§a login
vercel login

# Execute o deploy
vercel --prod
2. VariÃ¡veis de Ambiente
No dashboard da Vercel, configure:

OPENAI_API_KEY: Sua chave da API OpenAI
FLASK_ENV: production

3. DomÃ­nio Personalizado (Opcional)
Configure um domÃ­nio personalizado nas configuraÃ§Ãµes do projeto na Vercel.
ğŸ¨ Design e UX
Paleta de Cores (AutoU)

Laranja Principal: #FF6B35
Azul Principal: #1E40AF
Azul Escuro: #0F172A
Verde Sucesso: #10B981
Amarelo AtenÃ§Ã£o: #F59E0B

CaracterÃ­sticas do Design

âœ¨ AnimaÃ§Ãµes suaves para melhor experiÃªncia
ğŸ“± Design responsivo para todos os dispositivos
ğŸ¯ Foco na usabilidade com feedback visual claro
ğŸš€ Loading states para transparÃªncia do processo
ğŸ”” NotificaÃ§Ãµes para confirmaÃ§Ã£o de aÃ§Ãµes

ğŸ§  Como Funciona
1. Processamento de Input
python# Upload de arquivo ou texto direto
input â†’ EmailProcessor â†’ texto limpo
2. ClassificaÃ§Ã£o Inteligente
python# Duas estratÃ©gias de classificaÃ§Ã£o
texto â†’ OpenAI GPT-3.5 â†’ classificaÃ§Ã£o + confianÃ§a
   â†“ (fallback)
texto â†’ regras + palavras-chave â†’ classificaÃ§Ã£o
3. GeraÃ§Ã£o de Resposta
python# Resposta contextualizada
(email + classificaÃ§Ã£o) â†’ ResponseGenerator â†’ resposta personalizada
ğŸ“Š MÃ©tricas e Analytics
O sistema coleta automaticamente:

Total de anÃ¡lises realizadas
DistribuiÃ§Ã£o de classificaÃ§Ãµes (Produtivo vs Improdutivo)
MÃ©todos utilizados (OpenAI vs Regras)
Tipos de arquivo processados
Tempos de resposta mÃ©dios
Taxa de sucesso da aplicaÃ§Ã£o

Acesso Ã s MÃ©tricas
bashGET /api/metrics
ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas
PersonalizaÃ§Ãµes do Classificador
python# Adicionar palavras-chave personalizadas
productive_keywords = {
    'sua_palavra': peso,
    # ...
}
Ajuste de Templates de Resposta
python# Personalizar templates no response_generator.py
productive_templates = [
    "Seu template personalizado aqui..."
]
ğŸ› Troubleshooting
Problemas Comuns
1. Erro de API OpenAI
SoluÃ§Ã£o: Verifique se a OPENAI_API_KEY estÃ¡ configurada corretamente
2. Arquivo nÃ£o processado
SoluÃ§Ã£o: Verifique se o arquivo Ã© .txt ou .pdf e menor que 10MB
3. Deploy falha na Vercel
SoluÃ§Ã£o: Confirme que o vercel.json estÃ¡ na raiz e as dependÃªncias estÃ£o corretas
Logs e Debug
bash# Ativar modo debug local
export FLASK_DEBUG=True
python app.py
ğŸ§ª Testes
Casos de Teste IncluÃ­dos

Emails Produtivos:

SolicitaÃ§Ãµes de suporte
Problemas tÃ©cnicos
Pedidos de orÃ§amento
Agendamento de reuniÃµes


Emails Improdutivos:

FelicitaÃ§Ãµes
Agradecimentos
Mensagens sociais
Forwards informativos



Executar Testes
bash# Teste completo do sistema
python tests/test_classifier.py

# Teste especÃ­fico de componentes
python -m pytest tests/ -v

ğŸš€ PrÃ³ximas Melhorias
Funcionalidades Futuras

 Multi-idiomas (inglÃªs, espanhol)
 Categorias customizÃ¡veis pelo usuÃ¡rio
 IntegraÃ§Ã£o com email (IMAP/POP3)
 Dashboard de analytics visual
 API de webhook para integraÃ§Ãµes
 HistÃ³rico de classificaÃ§Ãµes
 Feedback do usuÃ¡rio para melhoria do modelo

Melhorias TÃ©cnicas

 Cache Redis para otimizaÃ§Ã£o
 Rate limiting por IP
 Logs estruturados com ELK Stack
 Monitoramento com health checks
 Testes de carga automatizados

ğŸ‘¥ ContribuiÃ§Ã£o
Como Contribuir

Fork o projeto
Crie uma branch para sua feature (git checkout -b feature/nova-feature)
Commit suas mudanÃ§as (git commit -m 'Adiciona nova feature')
Push para a branch (git push origin feature/nova-feature)
Abra um Pull Request

PadrÃµes de CÃ³digo

Python: PEP 8
JavaScript: ES6+ com comentÃ¡rios
CSS: BEM methodology
Commits: Conventional Commits

ğŸ“„ LicenÃ§a
Este projeto foi desenvolvido para o processo seletivo da AutoU.
ğŸ“ Contato
Desenvolvedor: Larissa Silva
Email: ls8730084@gmail.com
LinkedIn: https://www.linkedin.com/in/larissasilva-costa/

ğŸ¯ Sobre o Desafio AutoU
Este projeto foi desenvolvido como parte do processo seletivo da AutoU, demonstrando:

âœ… ResoluÃ§Ã£o de problemas complexos com tecnologia
âœ… Autonomia na escolha de ferramentas e abordagens
âœ… Foco na experiÃªncia do usuÃ¡rio final
âœ… Qualidade tÃ©cnica e boas prÃ¡ticas
âœ… Deploy funcional em ambiente de produÃ§Ã£o

CritÃ©rios Atendidos

âœ… Interface Web HTML com upload de arquivos
âœ… Backend Python com processamento NLP
âœ… ClassificaÃ§Ã£o IA usando OpenAI GPT
âœ… Respostas automÃ¡ticas contextualizadas
âœ… Hospedagem na nuvem (Vercel)
âœ… Design excepcional baseado na AutoU
âœ… Funcionalidades avanÃ§adas (mÃ©tricas, testes)

âš¡ Desenvolvido com paixÃ£o por tecnologia para a AutoU